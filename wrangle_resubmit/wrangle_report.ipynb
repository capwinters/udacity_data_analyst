{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report\n",
    "\n",
    "\n",
    "## Gathering\n",
    "\n",
    "* Source1 (twitter-archive-enhanced.csv): \n",
    "\n",
    "since it was a simple csv file, it was easy to read it into a dataframe.\n",
    "\n",
    "* Source2 (image-predictions.tsv): \n",
    "\n",
    "There was no authentication, merely a link to a tsv file. I downloaded it, wrote it to local and read it as a datafame. \n",
    "\n",
    "* Source 3 (Titter API): \n",
    "\n",
    "It was relatively challanging, but the API was straight forward. The only issue is that, it takes some time to fetch all the tweets. Therefore, once I got the information, I wrote it on a file. After that wrangle_act.ipynb notebook gives this part as a markup, so that evaluator can run all cells but not wait for the API everytime. \n",
    "\n",
    "\n",
    "## Assessment\n",
    "\n",
    "Here I figured out that dealing with all 3 files seperately is not the most efficient way. If were were working with bigger data, we may had to, but the structure of all 3 sources are luckily neat and all can be joined on twitter id. Here the critical thing is that tweet_ids were \"unique\" which made it very easy to outer* join all the tables and work on one single table. \n",
    "\n",
    "<div class=\"alert alert-block alert-success\">*The reason for outer join is that, at the first step we do not want to loose anything. At this level we are not sure if we need all the information from all tables or not.</div>\n",
    "\n",
    "### Iteration 1\n",
    "\n",
    "Due to the reasons mentioned above, I went through a simple iteration 1 phase and corrected necessray things like tweeter_id column name etc. \n",
    "\n",
    "### Iteration 2\n",
    "\n",
    "After ensuring that everything is joined as one, I found several quality and tidiness issues. Especially text column was hard to handle in jupyter notebook. During visual assessment  sometimes wrote them so a csv and opened it in excel, or casted it into a list() which ensures it is printed whole.  \n",
    "\n",
    "There were in total 9 quality, 3 tidiness issues. Some were very staightforward to get rid of, some were more challenging.  \n",
    "\n",
    "## Cleaning\n",
    "\n",
    "Some cleaning tasks were very simple row removals, but for others, since structure of every column is not well defined, I had to assume some conventions of my own: \n",
    "\n",
    "1. I assumed a dog can have only one stage, although data had multiple stages at the related clumns at first. \n",
    "2. I decided to remove every prediction that is not a breed of dog. \n",
    "\n",
    "Here, but the most challanging part was about the nnumerators and denominators. There were basically no rule, as this is an humorous twitter account. Nevertheless, some alternative usage of \"x/y\" format was leading to wrong values like 2/24, 9/11 etc. I detected these one by one and corrected where possible. \n",
    "\n",
    "## Reflections & Summary\n",
    "\n",
    "I think wrangling is by far the most diverse and challanging part of this program. Lack of rules and imperfection of data makes it hard to procceed. Knowing that any error you might do here, will eventually reflect to the results of your analysis makes this part very critical and stressfull and reminds me of the following quote/art work by Stefan Sagmeister:\n",
    "\n",
    "> [\"My obsessions make my life worse, but my work better\"](https://www.youtube.com/watch?v=vwILTvYUHX8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'wrangle_report.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
